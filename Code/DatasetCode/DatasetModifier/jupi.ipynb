{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [00:33<00:00, 32.52it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from Read_AllFiles import ReadFiles\n",
    "from numpy import save\n",
    "from tqdm import tqdm\n",
    "path = ('D:\\\\tuc\\\\exam10\\\\Thesis\\\\Dataset\\\\FIXED_CMU_BVH')\n",
    "out = ('D:\\\\tuc\\\\exam10\\\\Thesis\\\\Dataset\\\\CMU_nmpy\\\\')\n",
    "files=ReadFiles.getListOfFiles(None,path)\n",
    "\n",
    "for file in tqdm(files):\n",
    "    data = open(file, 'r')\n",
    "    Lines = data.readlines()\n",
    "    Hierarchy = Lines[:187]\n",
    "    Motion = Lines[187:]\n",
    "    arr = np.array(Motion)\n",
    "    name= out +file.split(\"\\\\\")[6].split(\".bvh\")[0] + '.npy'\n",
    "    save(name, arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from transforms3d.euler import euler2mat, mat2euler\n",
    "\n",
    "\n",
    "class BvhJoint:\n",
    "    def __init__(self, name, parent):\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        self.offset = np.zeros(3)\n",
    "        self.channels = []\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "\n",
    "    def position_animated(self):\n",
    "        return any([x.endswith('position') for x in self.channels])\n",
    "\n",
    "    def rotation_animated(self):\n",
    "        return any([x.endswith('rotation') for x in self.channels])\n",
    "\n",
    "\n",
    "class Bvh:\n",
    "    def __init__(self):\n",
    "        self.joints = {}\n",
    "        self.root = None\n",
    "        self.keyframes = None\n",
    "        self.frames = 0\n",
    "        self.fps = 0\n",
    "\n",
    "    def _parse_hierarchy(self, text):\n",
    "        lines = re.split('\\\\s*\\\\n+\\\\s*', text)\n",
    "\n",
    "        joint_stack = []\n",
    "\n",
    "        for line in lines:\n",
    "            words = re.split('\\\\s+', line)\n",
    "            instruction = words[0]\n",
    "\n",
    "            if instruction == \"JOINT\" or instruction == \"ROOT\":\n",
    "                parent = joint_stack[-1] if instruction == \"JOINT\" else None\n",
    "                joint = BvhJoint(words[1], parent)\n",
    "                self.joints[joint.name] = joint\n",
    "                if parent:\n",
    "                    parent.add_child(joint)\n",
    "                joint_stack.append(joint)\n",
    "                if instruction == \"ROOT\":\n",
    "                    self.root = joint\n",
    "            elif instruction == \"CHANNELS\":\n",
    "                for i in range(2, len(words)):\n",
    "                    joint_stack[-1].channels.append(words[i])\n",
    "            elif instruction == \"OFFSET\":\n",
    "                for i in range(1, len(words)):\n",
    "                    joint_stack[-1].offset[i - 1] = float(words[i])\n",
    "            elif instruction == \"End\":\n",
    "                joint = BvhJoint(joint_stack[-1].name + \"_end\", joint_stack[-1])\n",
    "                joint_stack[-1].add_child(joint)\n",
    "                joint_stack.append(joint)\n",
    "                self.joints[joint.name] = joint\n",
    "            elif instruction == '}':\n",
    "                joint_stack.pop()\n",
    "\n",
    "    def _add_pose_recursive(self, joint, offset, poses):\n",
    "        pose = joint.offset + offset\n",
    "        poses.append(pose)\n",
    "\n",
    "        for c in joint.children:\n",
    "            self._add_pose_recursive(c, pose, poses)\n",
    "\n",
    "    def plot_hierarchy(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "        poses = []\n",
    "        self._add_pose_recursive(self.root, np.zeros(3), poses)\n",
    "        pos = np.array(poses)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(pos[:, 0], pos[:, 2], pos[:, 1])\n",
    "        ax.set_xlim(-30, 30)\n",
    "        ax.set_ylim(-30, 30)\n",
    "        ax.set_zlim(-30, 30)\n",
    "        plt.show()\n",
    "\n",
    "    def parse_motion(self, text):\n",
    "        lines = re.split('\\\\s*\\\\n+\\\\s*', text)\n",
    "\n",
    "        frame = 0\n",
    "        for line in lines:\n",
    "            if line == '':\n",
    "                continue\n",
    "            words = re.split('\\\\s+', line)\n",
    "\n",
    "            if line.startswith(\"Frame Time:\"):\n",
    "                self.fps = round(1 / float(words[2]))\n",
    "                continue\n",
    "            if line.startswith(\"Frames:\"):\n",
    "                self.frames = len(lines)-4\n",
    "\n",
    "                continue\n",
    "\n",
    "            if self.keyframes is None:\n",
    "                self.keyframes = np.empty((self.frames, len(words)), dtype=np.float32)\n",
    "\n",
    "            for angle_index in range(len(words)):\n",
    "                self.keyframes[frame, angle_index] = float(words[angle_index])\n",
    "\n",
    "            frame += 1\n",
    "\n",
    "    def parse_string(self, text):\n",
    "        hierarchy, motion = text.split(\"MOTION\")\n",
    "        self._parse_hierarchy(hierarchy)\n",
    "        self.parse_motion(motion)\n",
    "\n",
    "    def _extract_rotation(self, frame_pose, index_offset, joint):\n",
    "        local_rotation = np.zeros(3)\n",
    "        for channel in joint.channels:\n",
    "            if channel.endswith(\"position\"):\n",
    "                continue\n",
    "            if channel == \"Xrotation\":\n",
    "                local_rotation[0] = frame_pose[index_offset]\n",
    "            elif channel == \"Yrotation\":\n",
    "                local_rotation[1] = frame_pose[index_offset]\n",
    "            elif channel == \"Zrotation\":\n",
    "                local_rotation[2] = frame_pose[index_offset]\n",
    "            else:\n",
    "                raise Exception(f\"Unknown channel {channel}\")\n",
    "            index_offset += 1\n",
    "\n",
    "        local_rotation = np.deg2rad(local_rotation)\n",
    "        M_rotation = np.eye(3)\n",
    "        for channel in joint.channels:\n",
    "            if channel.endswith(\"position\"):\n",
    "                continue\n",
    "\n",
    "            if channel == \"Xrotation\":\n",
    "                euler_rot = np.array([local_rotation[0], 0., 0.])\n",
    "            elif channel == \"Yrotation\":\n",
    "                euler_rot = np.array([0., local_rotation[1], 0.])\n",
    "            elif channel == \"Zrotation\":\n",
    "                euler_rot = np.array([0., 0., local_rotation[2]])\n",
    "            else:\n",
    "                raise Exception(f\"Unknown channel {channel}\")\n",
    "\n",
    "            M_channel = euler2mat(*euler_rot)\n",
    "            M_rotation = M_rotation.dot(M_channel)\n",
    "\n",
    "        return M_rotation, index_offset\n",
    "\n",
    "    def _extract_position(self, joint, frame_pose, index_offset):\n",
    "        offset_position = np.zeros(3)\n",
    "        for channel in joint.channels:\n",
    "            if channel.endswith(\"rotation\"):\n",
    "                continue\n",
    "            if channel == \"Xposition\":\n",
    "                offset_position[0] = frame_pose[index_offset]\n",
    "            elif channel == \"Yposition\":\n",
    "                offset_position[1] = frame_pose[index_offset]\n",
    "            elif channel == \"Zposition\":\n",
    "                offset_position[2] = frame_pose[index_offset]\n",
    "            else:\n",
    "                raise Exception(f\"Unknown channel {channel}\")\n",
    "            index_offset += 1\n",
    "\n",
    "        return offset_position, index_offset\n",
    "\n",
    "    def _recursive_apply_frame(self, joint, frame_pose, index_offset, p, r, M_parent, p_parent):\n",
    "        if joint.position_animated():\n",
    "            offset_position, index_offset = self._extract_position(joint, frame_pose, index_offset)\n",
    "        else:\n",
    "            offset_position = np.zeros(3)\n",
    "\n",
    "        if len(joint.channels) == 0:\n",
    "            joint_index = list(self.joints.values()).index(joint)\n",
    "            p[joint_index] = p_parent + M_parent.dot(joint.offset)\n",
    "            r[joint_index] = mat2euler(M_parent)\n",
    "            return index_offset\n",
    "\n",
    "        if joint.rotation_animated():\n",
    "            M_rotation, index_offset = self._extract_rotation(frame_pose, index_offset, joint)\n",
    "        else:\n",
    "            M_rotation = np.eye(3)\n",
    "\n",
    "        M = M_parent.dot(M_rotation)\n",
    "        position = p_parent + M_parent.dot(joint.offset) + offset_position\n",
    "\n",
    "        rotation = np.rad2deg(mat2euler(M))\n",
    "        joint_index = list(self.joints.values()).index(joint)\n",
    "        p[joint_index] = position\n",
    "        r[joint_index] = rotation\n",
    "\n",
    "        for c in joint.children:\n",
    "            index_offset = self._recursive_apply_frame(c, frame_pose, index_offset, p, r, M, position)\n",
    "\n",
    "        return index_offset\n",
    "\n",
    "    def frame_pose(self, frame):\n",
    "        p = np.empty((len(self.joints), 3))\n",
    "        r = np.empty((len(self.joints), 3))\n",
    "        frame_pose = self.keyframes[frame]\n",
    "        M_parent = np.zeros((3, 3))\n",
    "        M_parent[0, 0] = 1\n",
    "        M_parent[1, 1] = 1\n",
    "        M_parent[2, 2] = 1\n",
    "        self._recursive_apply_frame(self.root, frame_pose, 0, p, r, M_parent, np.zeros(3))\n",
    "\n",
    "        return p, r\n",
    "\n",
    "    def all_frame_poses(self):\n",
    "        p = np.empty((self.frames, len(self.joints), 3))\n",
    "        r = np.empty((self.frames, len(self.joints), 3))\n",
    "\n",
    "        for frame in range(len(self.keyframes)):\n",
    "            p[frame], r[frame] = self.frame_pose(frame)\n",
    "\n",
    "        return p, r\n",
    "\n",
    "    def _plot_pose(self, p, r, fig=None, ax=None):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "        if fig is None:\n",
    "            fig = plt.figure()\n",
    "        if ax is None:\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        ax.cla()\n",
    "        ax.scatter(p[:, 0], p[:, 2], p[:, 1])\n",
    "        ax.set_xlim(-30, 30)\n",
    "        ax.set_ylim(-30, 30)\n",
    "        ax.set_zlim(-1, 59)\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    def plot_frame(self, frame, fig=None, ax=None):\n",
    "        p, r = self.frame_pose(frame)\n",
    "        self._plot_pose(p, r, fig, ax)\n",
    "\n",
    "    def joint_names(self):\n",
    "        return self.joints.keys()\n",
    "\n",
    "    def parse_file(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            self.parse_string(f.read())\n",
    "\n",
    "    def plot_all_frames(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in range(self.frames):\n",
    "            self.plot_frame(i, fig, ax)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BVH {len(self.joints.keys())} joints, {self.frames} frames\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # create Bvh parser\n",
    "    anim = Bvh()\n",
    "    # parser file\n",
    "    anim.parse_file(\"D:\\\\tuc\\\\exam10\\\\Thesis\\\\Dataset\\\\FIXED_CMU_BVH\\\\02_01.bvh\")\n",
    "\n",
    "    # draw the skeleton in T-pose\n",
    "    anim.plot_hierarchy()\n",
    "\n",
    "    # extract single frame pose: axis0=joint, axis1=positionXYZ/rotationXYZ\n",
    "    p, r = anim.frame_pose(0)\n",
    "\n",
    "    # extract all poses: axis0=frame, axis1=joint, axis2=positionXYZ/rotationXYZ\n",
    "    all_p, all_r = anim.all_frame_poses()\n",
    "\n",
    "    # print all joints, their positions and orientations\n",
    "    for _p, _r, _j in zip(p, r, anim.joint_names()):\n",
    "        print(f\"{_j}: p={_p}, r={_r}\")\n",
    "\n",
    "    # draw the skeleton for the given frame\n",
    "    anim.plot_frame(22)\n",
    "\n",
    "    # show full animation\n",
    "    anim.plot_all_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1078/1078 [00:01<00:00, 542.35it/s]\n",
      "C:\\Users\\msi\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Sequential()\\nmodel.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences=True))\\nmodel.add(Dropout(0.2))\\nmodel.add(LSTM(256))\\nmodel.add(Dropout(0.2))\\nmodel.add(Dense(3, activation=\\'softmax\\'))\\nmodel.compile(loss = \\'categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\nmodel.summary()\\nprobability_model = tf.keras.Sequential([model, \\n                                         tf.keras.layers.Softmax()])\\nfilepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-biggeer.hdf5\"\\ncheckpoint = ModelCheckpoint(filepath, monitor=\\'loss\\', verbose = 1, save_best_only=True, mode = \\'min\\')\\ncallbacks_list = [checkpoint]\\n\\nmodel.fit(X, y, epochs = 30, batch_size=32, callbacks=callbacks_list)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Read_AllFiles import ReadFiles\n",
    "from numpy import load\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = ('D:\\\\tuc\\\\exam10\\\\Thesis\\\\Dataset\\\\CMU_nmpy\\\\')\n",
    "files=ReadFiles.getListOfFiles(None,path)\n",
    "x  = []\n",
    "y = []\n",
    "seq = []\n",
    "seq_len = 100\n",
    "for file in tqdm(files):\n",
    "    x.append(np.load(file))\n",
    "\n",
    "    \n",
    "\n",
    "X= np.asarray(x)\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-biggeer.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose = 1, save_best_only=True, mode = 'min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X, y, epochs = 30, batch_size=32, callbacks=callbacks_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"tensorflow/python/framework/cpp_shape_inference.proto\":\n  tensorflow.CppShapeInferenceResult.HandleShapeAndType.specialized_type: \".tensorflow.SpecializedType\" is not defined.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30856/1255983717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_options\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoShardPolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_options\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExternalStatePolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_six\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpp_shape_inference_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpydev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\cpp_shape_inference_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m DESCRIPTOR = _descriptor.FileDescriptor(\n\u001b[0m\u001b[0;32m     21\u001b[0m   \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tensorflow/python/framework/cpp_shape_inference.proto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m   \u001b[0mpackage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\protobuf\\descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[0;32m    981\u001b[0m           \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please link in cpp generated lib for %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mserialized_pb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAddSerializedFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized_pb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFileDescriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"tensorflow/python/framework/cpp_shape_inference.proto\":\n  tensorflow.CppShapeInferenceResult.HandleShapeAndType.specialized_type: \".tensorflow.SpecializedType\" is not defined.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense,MaxPooling1D,Softmax, LSTM, Dropout\n",
    "from tensorflow.keras import utils\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Read_AllFiles import ReadFiles\n",
    "from numpy import load\n",
    "from tqdm import tqdm\n",
    "###   (4320,150,13,2) ---->>>   (4320, 150, 26)\n",
    "\n",
    "#X = np.reshape(X, (X.shape[0], X.shape[1],X.shape[2]*X.shape[3]))\n",
    "#X= X/np.max(X)\n",
    "#print(X.shape)\n",
    "\n",
    "#y = utils.to_categorical(y)\n",
    "\n",
    "#print(y.shape)\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-biggeer.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose = 1, save_best_only=True, mode = 'min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X, y, epochs = 30, batch_size=32, callbacks=callbacks_list)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
